# üöÄ ML Project - Documenta√ß√£o Completa

## üìã Vis√£o Geral

O ML Project √© uma plataforma abrangente de automa√ß√£o de vendas para o Mercado Livre, incorporando Machine Learning, AutoML e intelig√™ncia artificial para otimizar estrat√©gias de vendas e maximizar resultados.

## üèóÔ∏è Arquitetura do Sistema

### Componentes Principais

#### 1. **AutoML (Novidade!)**
- **Localiza√ß√£o**: `/automl/`
- **Funcionalidades**:
  - Experimenta√ß√£o automatizada com `experiment.py`
  - Otimiza√ß√£o de hiperpar√¢metros com `tuning.py` 
  - Tracking de experimentos com MLflow via `tracking.py`
  - Integra√ß√£o com m√∫ltiplos algoritmos de ML

#### 2. **Backend Core**
- **Localiza√ß√£o**: `/backend/`
- **Tecnologia**: FastAPI + SQLAlchemy
- **Funcionalidades**: API REST, autentica√ß√£o, persist√™ncia

#### 3. **Servi√ßos Especializados**
- **Simulator Service**: Simula√ß√£o de campanhas e previs√µes
- **Learning Service**: Aprendizado cont√≠nuo e retreinamento
- **Optimizer AI**: Otimiza√ß√£o de textos e copywriting
- **Campaign Automation**: Automa√ß√£o de campanhas
- **Discount Scheduler**: Agendamento inteligente de descontos

#### 4. **Infraestrutura**
- **Docker**: Containeriza√ß√£o completa
- **PostgreSQL**: Banco de dados principal
- **Redis**: Cache e sess√µes
- **MLflow**: Tracking de experimentos ML
- **Nginx**: Proxy reverso e load balancing

## üöÄ Quick Start

### Pr√©-requisitos
- Docker e Docker Compose
- Python 3.11+
- Git

### Instala√ß√£o R√°pida

```bash
# 1. Clonar o reposit√≥rio
git clone <repository-url>
cd ml_project

# 2. Deploy com Docker
cd deploy
docker-compose up -d

# 3. Acessar aplica√ß√µes
# Backend API: http://localhost:8000
# MLflow UI: http://localhost:5000
# Grafana: http://localhost:3001
# Jupyter: http://localhost:8888
```

### Instala√ß√£o para Desenvolvimento

```bash
# 1. Instalar depend√™ncias do AutoML
cd automl
pip install -r requirements.txt

# 2. Instalar depend√™ncias do backend
cd ../backend
pip install -r requirements.txt

# 3. Configurar vari√°veis de ambiente
cp .env.example .env
# Editar .env com suas configura√ß√µes

# 4. Executar servi√ßos
uvicorn backend.app.main:app --reload
```

## ü§ñ AutoML - Guia Completo

### Experimenta√ß√£o Automatizada

```python
from automl.experiment import ExperimentManager

# Criar manager
manager = ExperimentManager("meu_experimento")

# Criar experimento
experiment_id = manager.create_experiment(
    name="Previs√£o de Vendas",
    description="Modelo para prever vendas baseado em caracter√≠sticas do produto",
    dataset_info={"shape": (1000, 10), "target": "vendas"}
)

# Executar experimento
results = manager.run_basic_experiment(
    experiment_id=experiment_id,
    X=X_data,
    y=y_data,
    problem_type="regression"
)
```

### Otimiza√ß√£o de Hiperpar√¢metros

```python
from automl.tuning import HyperparameterTuner
from sklearn.ensemble import RandomForestRegressor

# Criar tuner
tuner = HyperparameterTuner()

# Otimizar modelo
model = RandomForestRegressor(random_state=42)
results = tuner.auto_tune_model(
    model=model,
    model_type="random_forest_regressor",
    X=X_data,
    y=y_data,
    method="random_search"
)
```

### Tracking com MLflow

```python
from automl.tracking import create_tracker

# Criar tracker
tracker = create_tracker("meus_experimentos")

# Rastrear experimento
run_id = tracker.track_automl_experiment(
    experiment_results=results,
    dataset_info=dataset_info
)
```

## üìä Exemplos Pr√°ticos

### An√°lise de Concorr√™ncia
- **Notebook**: `/examples/concorrencia_exemplo.ipynb`
- **Objetivo**: Analisar dados de concorrentes e otimizar pre√ßos
- **Dados**: Dataset simulado com 1000+ produtos
- **Modelos**: Random Forest, Linear Regression
- **Sa√≠das**: Insights acion√°veis e recomenda√ß√µes

### Casos de Uso Comuns

1. **Precifica√ß√£o Din√¢mica**
   ```python
   # Usar AutoML para determinar pre√ßo √≥timo
   price_model = manager.run_basic_experiment(
       experiment_id="price_optimization",
       X=product_features,
       y=optimal_prices,
       problem_type="regression"
   )
   ```

2. **Previs√£o de Demanda**
   ```python
   # Prever demanda futura
   demand_model = tuner.auto_tune_model(
       model=XGBRegressor(),
       model_type="gradient_boosting",
       X=historical_data,
       y=demand_data
   )
   ```

3. **Segmenta√ß√£o de Clientes**
   ```python
   # Clustering autom√°tico
   clustering_results = manager.run_basic_experiment(
       experiment_id="customer_segmentation",
       X=customer_features,
       y=None,  # Unsupervised
       problem_type="clustering"
   )
   ```

## üê≥ Deploy e Produ√ß√£o

### Ambiente de Produ√ß√£o

```bash
# Deploy completo com monitoramento
cd deploy
docker-compose -f docker-compose.yaml up -d

# Verificar status
docker-compose ps
docker-compose logs backend
```

### Configura√ß√µes de Produ√ß√£o

#### Vari√°veis de Ambiente Cr√≠ticas
```env
# Seguran√ßa
SECRET_KEY=your-super-secret-key-here
ML_CLIENT_ID=your-mercado-livre-client-id
ML_CLIENT_SECRET=your-mercado-livre-client-secret

# Database
DATABASE_URL=postgresql+psycopg2://postgres:postgres@db:5432/ml_db
REDIS_URL=redis://db:6379

# MLflow
MLFLOW_TRACKING_URI=postgresql+psycopg2://postgres:postgres@db:5432/ml_db

# Email (para alertas)
SMTP_SERVER=smtp.gmail.com
SMTP_USER=your-email@gmail.com
SMTP_PASSWORD=your-app-password
```

#### Monitoramento
- **Prometheus**: M√©tricas de sistema e aplica√ß√£o
- **Grafana**: Dashboards visuais
- **Health Checks**: Endpoints `/health` em todos os servi√ßos
- **Logs**: Estruturados e centralizados

## üîß Configura√ß√£o Avan√ßada

### MLflow Tracking Server

```bash
# Configurar MLflow com PostgreSQL
mlflow server \
  --backend-store-uri postgresql+psycopg2://postgres:postgres@db:5432/ml_db \
  --default-artifact-root /path/to/artifacts \
  --host 0.0.0.0 \
  --port 5000
```

### Escalabilidade

#### Kubernetes (Futuro)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ml-project-backend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ml-project-backend
  template:
    metadata:
      labels:
        app: ml-project-backend
    spec:
      containers:
      - name: backend
        image: ml-project/backend:latest
        ports:
        - containerPort: 8000
```

## üìà Monitoramento e M√©tricas

### M√©tricas Principais
- **Experimentos**: Taxa de sucesso, tempo de execu√ß√£o
- **Modelos**: Accuracy, precision, recall, F1-score
- **Sistema**: CPU, mem√≥ria, rede, disco
- **Neg√≥cio**: ROI, convers√µes, vendas

### Alertas Configurados
- Falha em experimentos cr√≠ticos
- Performance de modelo abaixo do threshold
- Recursos de sistema em limite
- Erro em APIs externas

## üîí Seguran√ßa

### Pr√°ticas Implementadas
- **Autentica√ß√£o**: JWT tokens
- **Autoriza√ß√£o**: RBAC (Role-Based Access Control)
- **Criptografia**: Dados sens√≠veis em repouso
- **HTTPS**: TLS 1.3 em produ√ß√£o
- **Rate Limiting**: Prote√ß√£o contra abuso
- **Input Validation**: Sanitiza√ß√£o de dados

### Compliance
- **LGPD**: Prote√ß√£o de dados pessoais
- **SOC 2**: Controles de seguran√ßa
- **ISO 27001**: Gest√£o de seguran√ßa da informa√ß√£o

## üîÑ CI/CD

### Pipeline Automatizado
1. **Lint**: Verifica√ß√£o de c√≥digo
2. **Test**: Testes unit√°rios e integra√ß√£o
3. **Security**: Scan de vulnerabilidades
4. **Build**: Cria√ß√£o de imagens Docker
5. **Deploy**: Deploy automatizado

### Configura√ß√£o GitHub Actions
```yaml
name: CI/CD Pipeline
on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Run AutoML tests
        run: |
          cd automl
          pip install -r requirements.txt
          python -m pytest tests/
```

## üß™ Testes

### Estrutura de Testes
- **Unit√°rios**: `/tests/test_*.py`
- **Integra√ß√£o**: `/tests/test_integration.py`
- **E2E**: `/tests/test_e2e_*.py`
- **AutoML**: `/tests/test_experiment.py`

### Executar Testes
```bash
# Todos os testes
pytest tests/

# Apenas AutoML
pytest tests/test_experiment.py

# Com coverage
pytest --cov=automl tests/
```

## üìö API Reference

### AutoML Endpoints

#### Experimentos
- `POST /api/automl/experiments` - Criar experimento
- `GET /api/automl/experiments/{id}` - Obter experimento
- `GET /api/automl/experiments` - Listar experimentos

#### Modelos
- `POST /api/automl/models/train` - Treinar modelo
- `POST /api/automl/models/predict` - Fazer predi√ß√£o
- `GET /api/automl/models/{id}/metrics` - M√©tricas do modelo

#### Tracking
- `GET /api/automl/tracking/runs` - Listar runs
- `GET /api/automl/tracking/experiments` - Listar experimentos
- `POST /api/automl/tracking/compare` - Comparar runs

## üîÆ Roadmap Futuro

### Pr√≥ximas Funcionalidades
1. **AutoML Avan√ßado**: Neural Architecture Search (NAS)
2. **Deep Learning**: Integra√ß√£o com PyTorch/TensorFlow
3. **Real-time ML**: Streaming ML com Kafka
4. **Explainable AI**: SHAP, LIME integration
5. **Multi-tenant**: Suporte a m√∫ltiplos clientes

### Melhorias Planejadas
- **Performance**: Caching inteligente
- **UX**: Interface web para AutoML
- **Automa√ß√£o**: Auto-deployment de modelos
- **Integra√ß√£o**: Mais marketplaces

## üÜò Troubleshooting

### Problemas Comuns

#### MLflow n√£o inicia
```bash
# Verificar logs
docker-compose logs mlflow

# Resetar banco
docker-compose down -v
docker-compose up -d postgres
docker-compose up -d mlflow
```

#### Experimentos falham
```bash
# Verificar depend√™ncias
pip install -r automl/requirements.txt

# Verificar logs
tail -f automl_results/experiment_*.log
```

#### Performance lenta
```bash
# Verificar recursos
docker stats

# Otimizar par√¢metros
# Reduzir n_iter em hyperparameter tuning
# Usar cv=3 em vez de cv=5
```

## üìû Suporte

### Canais de Suporte
- **Issues**: GitHub Issues para bugs
- **Discussions**: GitHub Discussions para d√∫vidas
- **Email**: support@mlproject.com
- **Slack**: #ml-project-support

### Contribui√ß√£o
1. Fork o reposit√≥rio
2. Crie uma branch feature
3. Commit suas mudan√ßas
4. Push para a branch
5. Abra um Pull Request

---

**Desenvolvido pela ML Project Team** üöÄ  
**Vers√£o**: 2.0  
**√öltima atualiza√ß√£o**: Dezembro 2024